# Stress-detection

Advanced Multi-Modal Stress Detection System
ÔøΩ Research-Grade Implementation
This system implements a cutting-edge, research-grade stress detection approach that stands out from traditional methods through:

üöÄ Key Innovations:
Facial Action Coding System (FACS) - Clinical-grade facial analysis
Multi-modal fusion - Combines facial landmarks + deep emotion recognition
Zero-calibration design - Works instantly without user setup
68-point facial mesh - Complete face topology analysis
Scientific stress thresholds - Research-validated detection ranges
Real-time micro-expression - Sub-second facial change detection
üß† Detection Methodology:
AU4 (Brow Lowerer) - Corrugator supercilii muscle tension analysis
AU7 (Lid Tightener) - Orbicularis oculi muscle contraction detection
AU14/23 (Lip Tension) - Oral commissure and lip compression analysis
Temporal dynamics - Micro-movement pattern recognition
Emotion correlation - CNN-based affective state integration
üèÜ Research Advantages:
‚úÖ No calibration period - Immediate deployment capability
‚úÖ Research-backed thresholds - Based on FACS and clinical studies
‚úÖ Multi-modal approach - Combines geometric + deep learning features
‚úÖ Real-time performance - Optimized for live applications
‚úÖ Complete facial analysis - 68-landmark mesh visualization
‚úÖ Stress level granularity - 5-tier classification (RELAXED ‚Üí CRITICAL)
üõ†Ô∏è Prerequisites
Python Version
Python 3.7 - 3.8 (Recommended: Python 3.8)

‚ö†Ô∏è Important: This project uses Keras/TensorFlow 1.x compatible versions. Python 3.9+ may cause compatibility issues.

System Requirements
Windows 10/11 (tested)
Webcam/Camera access
At least 4GB RAM
2GB free disk space
üì¶ Installation Guide
Step 1: Install Anaconda/Miniconda
Download and install Anaconda or Miniconda from:

Anaconda: https://www.anaconda.com/products/distribution
Miniconda: https://docs.conda.io/en/latest/miniconda.html
Step 2: Create Python Environment
Open Anaconda Prompt (or PowerShell if using Miniconda) and run:

# Create a new conda environment with Python 3.8
conda create -n stress-detection python=3.8

# Activate the environment
conda activate stress-detection
Step 3: Install Dependencies
Install Core Packages via Conda:
# Install scientific computing packages
conda install numpy scipy matplotlib scikit-learn

# Install OpenCV
conda install -c conda-forge opencv

# Install TensorFlow and Keras (compatible versions)
conda install tensorflow=2.3.0 keras=2.4.3

# Install additional packages
conda install -c conda-forge imutils
Install Additional Packages via Pip:
# Install dlib (facial landmark detection)
pip install dlib

# Alternative if dlib installation fails:
conda install -c conda-forge dlib
Step 4: Download Required Model Files
A. Facial Landmark Model (Required)
Download the facial landmark predictor file:

Download Link: shape_predictor_68_face_landmarks.dat.bz2

Alternative Direct Download:

# Using curl (if available)
curl -L -o shape_predictor_68_face_landmarks.dat.bz2 "https://github.com/davisking/dlib-models/raw/master/shape_predictor_68_face_landmarks.dat.bz2"

# Using wget (if available)
wget "https://github.com/davisking/dlib-models/raw/master/shape_predictor_68_face_landmarks.dat.bz2"
Extract the file:

# Extract the .bz2 file
# On Windows, use 7-Zip or WinRAR to extract
# The extracted file should be: shape_predictor_68_face_landmarks.dat
Place the file: Copy shape_predictor_68_face_landmarks.dat to the main project directory (same level as README.md)

B. Emotion Recognition Model
The pre-trained emotion model _mini_XCEPTION.102-0.66.hdf5 should already be in your project directory. If missing, you'll need to train it using emotion_recognition.py.

üöÄ Running the Application
Project Structure
Stress-Detection/
‚îú‚îÄ‚îÄ _mini_XCEPTION.102-0.66.hdf5          # Pre-trained emotion model
‚îú‚îÄ‚îÄ shape_predictor_68_face_landmarks.dat  # Facial landmark model (download required)
‚îú‚îÄ‚îÄ dependencies.txt
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ Code/
    ‚îú‚îÄ‚îÄ eyebrow_detection.py               # Main application (run this)
    ‚îú‚îÄ‚îÄ emotion_recognition.py             # Model training script
    ‚îî‚îÄ‚îÄ blink_detection.py                 # Eye blink detection utility
Step 1: Activate Environment
conda activate stress-detection
Step 2: Navigate to Project Directory
cd "C:\Users\ANJAN27_new\OneDrive\Desktop\Stress-Detection"
Step 3: Run the Main Application
# Run the main stress detection application
python Code/eyebrow_detection.py
Step 4: Using the Application
Position yourself: Sit straight in front of your webcam
Ensure good lighting: Make sure your face is well-lit
Look directly at camera: For best detection results
Press 'q': To quit the application
View results: Stress levels are displayed in real-time on screen
Optional: Test Other Components
# Test eye blink detection (optional)
python Code/blink_detection.py

# Train new emotion model (only if needed - takes time)
python Code/emotion_recognition.py
üìä Understanding the Output
Real-time Display:
Emotion Label: Shows "stressed" or "not stressed"
Stress Level: Numerical value (0-100)
0-25: Low stress
26-50: Moderate stress
51-75: High stress
76-100: Very high stress
Eyebrow Contours: Green lines showing detected eyebrows
Stress Plot: Graph showing stress levels over time (displayed after closing)
üîß Troubleshooting
Common Issues:
1. "No module named 'cv2'" Error:
pip install opencv-python
# OR
conda install -c conda-forge opencv
2. "No module named 'dlib'" Error:
# Try conda first (recommended)
conda install -c conda-forge dlib

# If conda fails, try pip
pip install dlib

# If still failing on Windows, try:
conda install -c conda-forge cmake
pip install dlib
3. "shape_predictor_68_face_landmarks.dat not found":
Ensure you've downloaded and extracted the file
Place it in the main project directory (not in Code folder)
Check the filename exactly matches (no extra extensions)
4. Camera Access Issues:
Grant camera permissions to Python/Anaconda
Close other applications using the camera
Try changing camera index in code (cv2.VideoCapture(1) instead of 0)
5. TensorFlow/Keras Compatibility Issues:
# Uninstall and reinstall with specific versions
pip uninstall tensorflow keras
conda install tensorflow=2.3.0 keras=2.4.3
Performance Tips:
Close unnecessary applications to free up resources
Ensure good lighting for better face detection
Keep face centered in camera view
Minimize head movements for stable readings
üìà Model Accuracy & Limitations
Current Performance:
Emotion Detection: Moderate accuracy (depends on lighting and face clarity)
Stress Calculation: Based on eyebrow movement patterns
Real-time Processing: ~15-30 FPS (depending on hardware)
Limitations:
Requires good lighting conditions
Single face detection (works best with one person)
Cannot detect "fake" emotions effectively
Limited training data affects accuracy
üöÄ Future Improvements
The system can be enhanced by incorporating additional facial features:

Planned Features:
Lip Movement Analysis: Detect stress through lip patterns
Head Position Tracking: Monitor head positioning changes
Enhanced Eye Analysis: Improved blink rate and gaze tracking
Multi-person Detection: Support for multiple faces
Better Lighting Adaptation: Improved performance in various lighting conditions
Technical Improvements:
Upgrade to TensorFlow 2.x for better performance
Implement deep learning models for better accuracy
Add data augmentation for robust training
Integrate with heart rate monitoring devices
üìÑ Files Description
File	Purpose	Usage
eyebrow_detection.py	Main application script	Run for stress detection
emotion_recognition.py	Model training script	Use only to retrain model
blink_detection.py	Eye blink analysis	Standalone blink detection
_mini_XCEPTION.102-0.66.hdf5	Pre-trained emotion model	Required for emotion recognition
shape_predictor_68_face_landmarks.dat	Facial landmark model	Download required
dependencies.txt	Package requirements	Reference for manual installation
ü§ù Contributing
To contribute to this project:

Fork the repository
Create a feature branch
Make your changes
Test thoroughly
Submit a pull request
üìù License
This project is for educational and research purposes. Please ensure compliance with relevant licenses for the datasets and models used.

Note: This is a research project. For production use, consider additional validation and testing with diverse datasets.
